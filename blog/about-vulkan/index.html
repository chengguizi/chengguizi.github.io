<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="generator" content="Docusaurus v2.0.0-alpha.61">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous"><title data-react-helmet="true">About Vulkan and Future of High Performance Computing | My Logs</title><meta data-react-helmet="true" property="og:title" content="About Vulkan and Future of High Performance Computing | My Logs"><meta data-react-helmet="true" name="description" content="Towards a heterogeneous &amp; parallel computing architecture"><meta data-react-helmet="true" property="og:description" content="Towards a heterogeneous &amp; parallel computing architecture"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link rel="stylesheet" href="/styles.ef3fd247.css">
<link rel="preload" href="/styles.0a4195cd.js" as="script">
<link rel="preload" href="/runtime~main.0a9401a8.js" as="script">
<link rel="preload" href="/main.cb1cffdb.js" as="script">
<link rel="preload" href="/1.2d582883.js" as="script">
<link rel="preload" href="/2.2b91fbf4.js" as="script">
<link rel="preload" href="/3.88e3f531.js" as="script">
<link rel="preload" href="/ccc49370.75c65c31.js" as="script">
<link rel="preload" href="/9ea8503f.fe1359cf.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<nav class="navbar navbar--light navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand" href="/"><img class="navbar__logo" src="/img/logo.svg" alt="My Site Logo"><strong class="navbar__title">My Logs</strong></a><div class="navbar__item dropdown dropdown--hoverable dropdown--left"><a class="navbar__item navbar__link" href="/docs/hardware/">Hardware</a><ul class="dropdown__menu"><li><a class="dropdown__link" position="left" href="/docs/hardware/jetson/flash-existing-image">Jetson TX2</a></li><li><a class="dropdown__link" position="left" href="/docs/hardware/cameras/tiscamera-install">Cameras</a></li><li><a class="dropdown__link" position="left" href="/docs/hardware/px4-firmware/time-synchronisation">PX4 Firmware</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--left"><a class="navbar__item navbar__link" href="/docs/systems/vicon">Systems</a><ul class="dropdown__menu"><li><a class="dropdown__link" position="left" href="/docs/systems/ddrone_v2/ddrone">Ddrone V2</a></li><li><a class="dropdown__link" position="left" href="/docs/systems/unity-SITL">Simulations</a></li><li><a class="dropdown__link" position="left" href="/docs/systems/vicon">Vicon</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--left"><a class="navbar__item navbar__link" href="/docs/linux/desktop/gnome-shell-extensions">Linux</a><ul class="dropdown__menu"><li><a class="dropdown__link" position="left" href="/docs/linux/desktop/gnome-shell-extensions">Desktop</a></li><li><a class="dropdown__link" position="left" href="/docs/linux/packages/file-systems">Software Packages</a></li><li><a class="dropdown__link" position="left" href="/docs/linux/ros/using-catkin-build">ROS</a></li><li><a class="dropdown__link" position="left" href="/docs/linux/kernel/grub-default-kernel">Drivers &amp; Kernel</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--left"><a class="navbar__item navbar__link" href="/docs/productivity/git/git">Productivity</a><ul class="dropdown__menu"><li><a class="dropdown__link" position="left" href="/docs/productivity/git/git">Git Version Control</a></li><li><a class="dropdown__link" position="left" href="/docs/productivity/cmake_debug/cmake">CMake and Debugging</a></li><li><a class="dropdown__link" position="left" href="/docs/productivity/uiux/pangolin">UI/UX Tools</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--left"><a class="navbar__item navbar__link" href="/docs/research/">Research</a><ul class="dropdown__menu"><li><a class="dropdown__link" position="left" href="/docs/research/calibration/index">Sensor Calibration</a></li><li><a class="dropdown__link" position="left" href="/docs/research/vio/basalt-backend">VIO</a></li></ul></div><a class="navbar__item navbar__link" href="/docs/examples/doc1">Examples</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/chengguizi/chengguizi.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub</a><div class="react-toggle react-toggle--disabled displayOnlyInLargeViewport_2aTZ"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_BsTx">🌜</span></div><div class="react-toggle-track-x"><span class="toggle_BsTx">🌞</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" disabled="" aria-label="Dark mode toggle" class="react-toggle-screenreader-only"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/"><img class="navbar__logo" src="/img/logo.svg" alt="My Site Logo"><strong class="navbar__title">My Logs</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link menu__link--sublist" href="/docs/hardware/">Hardware</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/hardware/jetson/flash-existing-image">Jetson TX2</a></li><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/hardware/cameras/tiscamera-install">Cameras</a></li><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/hardware/px4-firmware/time-synchronisation">PX4 Firmware</a></li></ul></li><li class="menu__list-item"><a class="menu__link menu__link--sublist" href="/docs/systems/vicon">Systems</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/systems/ddrone_v2/ddrone">Ddrone V2</a></li><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/systems/unity-SITL">Simulations</a></li><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/systems/vicon">Vicon</a></li></ul></li><li class="menu__list-item"><a class="menu__link menu__link--sublist" href="/docs/linux/desktop/gnome-shell-extensions">Linux</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/linux/desktop/gnome-shell-extensions">Desktop</a></li><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/linux/packages/file-systems">Software Packages</a></li><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/linux/ros/using-catkin-build">ROS</a></li><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/linux/kernel/grub-default-kernel">Drivers &amp; Kernel</a></li></ul></li><li class="menu__list-item"><a class="menu__link menu__link--sublist" href="/docs/productivity/git/git">Productivity</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/productivity/git/git">Git Version Control</a></li><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/productivity/cmake_debug/cmake">CMake and Debugging</a></li><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/productivity/uiux/pangolin">UI/UX Tools</a></li></ul></li><li class="menu__list-item"><a class="menu__link menu__link--sublist" href="/docs/research/">Research</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/research/calibration/index">Sensor Calibration</a></li><li class="menu__list-item"><a class="menu__link" position="left" href="/docs/research/vio/basalt-backend">VIO</a></li></ul></li><li class="menu__list-item"><a class="menu__link" href="/docs/examples/doc1">Examples</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link navbar__link--active" href="/blog">Blog</a></li><li class="menu__list-item"><a href="https://github.com/chengguizi/chengguizi.github.io" target="_blank" rel="noopener noreferrer" class="menu__link">GitHub</a></li></ul></div></div></div></nav><div class="main-wrapper"><div class="container margin-vert--lg"><div class="row"><div class="col col--8 col--offset-2"><article><header><h1 class="margin-bottom--sm blogPostTitle_1mse">About Vulkan and Future of High Performance Computing</h1><div class="margin-vert--md"><time datetime="2020-05-26T00:00:00.000Z" class="blogPostDate_3bQP">May 26, 2020  · 7 min read</time></div><div class="avatar margin-vert--md"><div class="avatar__intro"><h4 class="avatar__name"><a href="https://github.com/chengguizi" target="_blank" rel="noreferrer noopener">Huimin C.</a></h4><small class="avatar__subtitle"></small></div></div></header><section class="markdown"><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="towards-a-heterogeneous--parallel-computing-architecture"></a>Towards a heterogeneous &amp; parallel computing architecture<a aria-hidden="true" tabindex="-1" class="hash-link" href="#towards-a-heterogeneous--parallel-computing-architecture" title="Direct link to heading">#</a></h2><p>OpenCL and Vulkan in the future would <a href="https://pcper.com/2017/05/breaking-opencl-merging-roadmap-into-vulkan/" target="_blank" rel="noopener noreferrer">probably</a> become the same thing. <a href="https://github.com/KhronosGroup/Vulkan-Ecosystem/issues/42#issuecomment-450966378" target="_blank" rel="noopener noreferrer">[1]</a><a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Vulkan-OpenCL-Interop-2019" target="_blank" rel="noopener noreferrer">[2]</a></p><p>To utilise the power of Vulkan (and OpenCL) we do not have to code it our own, espectially for the purpose of deep learning.</p><p>By the way, some framework utilise OpenGL (Compute Shader API) as well, a higher level API.</p><p>Mali-G series GPU supports <a href="https://en.wikipedia.org/wiki/Mali_(GPU)" target="_blank" rel="noopener noreferrer">OpenCL 2.0 full profile</a>.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="good-reads-for-mobile-dl"></a>Good Reads for Mobile DL<a aria-hidden="true" tabindex="-1" class="hash-link" href="#good-reads-for-mobile-dl" title="Direct link to heading">#</a></h2><p>Neural Network Inference on Mobile SoCs
<a href="https://arxiv.org/pdf/1908.11450.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1908.11450.pdf</a></p><p>A First Look at Deep Learning Apps on Smartphones
<a href="https://arxiv.org/pdf/1812.05448.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1812.05448.pdf</a></p><p>AI Benchmark: Running Deep Neural Networks on Android Smartphones
<a href="https://arxiv.org/pdf/1810.01109.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1810.01109.pdf</a></p><ul><li>good review of the SoCs (Hardware Acceleration, different SDKs)</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="chips-for-consideration"></a>Chips for Consideration<a aria-hidden="true" tabindex="-1" class="hash-link" href="#chips-for-consideration" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="without-npus"></a>without NPUs<a aria-hidden="true" tabindex="-1" class="hash-link" href="#without-npus" title="Direct link to heading">#</a></h3><p><strong>NXP</strong> </p><p>iMX6 or iMX8 - popular for general and multimedia usage.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="with-npus"></a>with NPUs<a aria-hidden="true" tabindex="-1" class="hash-link" href="#with-npus" title="Direct link to heading">#</a></h3><p><strong>Amlogic</strong></p><p>Amlogic A331D (with NPU) (Khadas VIM3)</p><p>Amlogic S922X (ODROID-N2)</p><p>Their own <a href="https://www.cnx-software.com/2020/01/13/getting-started-with-amlogic-npu-on-khadas-vim3-vim3l/" target="_blank" rel="noopener noreferrer">SDK</a></p><p><a href="https://www.khadas.com/vim" target="_blank" rel="noopener noreferrer">Board manufacturer</a>
<img src="https://static.wixstatic.com/media/04a2a6_e620b55023224a4faeff88c5bf540edb~mv2.jpg/v1/fill/w_395,h_394,al_c,q_80,usm_0.66_1.00_0.01/vim3.webp"></p><p>No known popular usage.</p><p><strong>RockChip</strong></p><p>Popular chip used in hobbists and multimedia products. Contribute significantly to open source community.</p><p>RockChip is upgrading their product line <a href="https://www.96rocks.com/blog/2019/11/25/rockchip-2020-roadmap-update/" target="_blank" rel="noopener noreferrer">this year 2020</a> with RK3588. their flagship RK3399 is getting dated. To be equipped with NPUs.</p><p><em>RK1808, RK1806 are supported by Baidu Paddle.</em> Only single camera input is supported.</p><p><strong>MediaTek(APU)</strong></p><p>MT8168, MT8175 (Mali G52, with APU 0.3TOPS, 2 CSI camera interface)</p><ul><li>only chips available?</li></ul><p><a href="https://www.mediatek.com/innovations/artificial-intelligence" target="_blank" rel="noopener noreferrer">MediaTek NeuroPilot SDK (Andriod only)</a></p><p><em>Supported by Baidu Paddle using API conversion.</em></p><p>Newer series</p><p>MediaTek helio</p><ul><li>P60 280GMAC/s</li><li>P90 APU 2.0 @  1165GMAC/s</li></ul><p><em>No available development boards</em></p><p><strong>Kirin</strong></p><p>Kirin970 and Kirin980 uses Cambricon Technologies. (supported by HiAI DDK(v100), but only Andriod?)
Kirin 810 and 820 and Kirin 990 uses Da Vinci NPU</p><p><em>Da Vinci NPU is supported by <a href="https://paddle-lite.readthedocs.io/zh/latest/demo_guides/npu.html" target="_blank" rel="noopener noreferrer">Baidu Paddle</a> using API conversion.</em> No development board available.</p><p><strong>HiSilicon</strong></p><p>Hi3516A(V300) - NNIE 1.0 TOPS (ARM A7)</p><p>Hi3519A(V100) - NNIE 2.0 TOPS @ 2W (ARM A53) <a href="http://www.tongyetech.com/product_service.html" target="_blank" rel="noopener noreferrer">Taobao</a></p><p><img src="https://img.alicdn.com/img/bao/uploaded/i4/i3/4019831782/O1CN01HqBoiP1P2CMWRPFND_!!4019831782.png_540x540Q50s50.jpg"></p><p>Hi3559A(V100) - Dual <a href="http://www.hisilicon.com/en/Media-Center/News/CES2018_hisilicon_hi3559a_AI" target="_blank" rel="noopener noreferrer">NNIE</a>@840MHz (much more powerful CPU, ARM A73 + A53) <a href="https://item.taobao.com/item.htm?spm=a230r.1.14.35.2ea1402fLbEjiT&amp;id=596309235525&amp;ns=1&amp;abbucket=4#detail" target="_blank" rel="noopener noreferrer">Taobao (huge size)</a></p><p><img src="https://pic4.zhimg.com/80/v2-d838c6d5739b10d3d9660490087da6dd_720w.jpg"></p><p><img src="https://pic4.zhimg.com/80/v2-02b4e71d79f75f962c5daa52c32e9b17_720w.jpg"></p><p><a href="http://www.hisilicon.com/en/Products/ProductList/Camera" target="_blank" rel="noopener noreferrer">http://www.hisilicon.com/en/Products/ProductList/Camera</a></p><p><a href="https://blog.csdn.net/zh8706/article/details/94554337" target="_blank" rel="noopener noreferrer">Custom SDK</a> May not be easy to use.</p><p><a href="https://blog.csdn.net/zh8706/article/details/100040675" target="_blank" rel="noopener noreferrer">Benchmark</a>
<a href="https://blog.csdn.net/yunge812/article/details/103938693" target="_blank" rel="noopener noreferrer">Other Blog</a> Yolov3 8fps, slightly better than TX1? Inferior than TX2.</p><p><strong>Horizon Robotics</strong></p><p>BOOTPRINT X2 96Boards ( Sunrise 2.0 AI edge processor - 4 TOPS@2W )</p><p><img src="https://www.cnx-software.com/wp-content/uploads/2019/11/BOOTPRINT-X2.jpg"></p><p><em>Uncertainty facing a start-up product</em></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="bottomline"></a>Bottomline<a aria-hidden="true" tabindex="-1" class="hash-link" href="#bottomline" title="Direct link to heading">#</a></h3><ul><li>Current Multimedia SoC are adding in NPUs quickly, but with custom SDKs mainly</li><li>Start up SoC is still largely uncertain its sustainability</li><li>Do no expect too much from the built-in NPU performance. More like a off-loading.</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="dl-framework-comparisons"></a>DL Framework Comparisons<a aria-hidden="true" tabindex="-1" class="hash-link" href="#dl-framework-comparisons" title="Direct link to heading">#</a></h2><p>overview of mobile DL framwork: <a href="https://easyai.tech/blog/10-mobil-deeplearning-frame/" target="_blank" rel="noopener noreferrer">https://easyai.tech/blog/10-mobil-deeplearning-frame/</a></p><p>嵌入式Linux平台部署AI神经网络模型Inference的方案 <a href="https://www.jianshu.com/p/d4425b65c6e6" target="_blank" rel="noopener noreferrer">https://www.jianshu.com/p/d4425b65c6e6</a></p><p>Future of GPU-based High Performance Computing (NPU to replace GPU) <a href="https://zhuanlan.zhihu.com/p/114254288" target="_blank" rel="noopener noreferrer">https://zhuanlan.zhihu.com/p/114254288</a></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="tensorflow-lite"></a>Tensorflow Lite<a aria-hidden="true" tabindex="-1" class="hash-link" href="#tensorflow-lite" title="Direct link to heading">#</a></h3><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="not-recommaned"></a>Not Recommaned<a aria-hidden="true" tabindex="-1" class="hash-link" href="#not-recommaned" title="Direct link to heading">#</a></h4><p>Mainly focused on Andriod and iOS, so not so friendly for our Robotics use, less documentation and popularity.</p><p><a href="https://blog.tensorflow.org/2019/01/tensorflow-lite-now-faster-with-mobile.html" target="_blank" rel="noopener noreferrer">Blog: TensorFlow Lite Now Faster with Mobile GPUs</a> This blog shows that only Andriod and iOS are officially supported (basically what Google has in mind).</p><p>Note: the full version of Tensorflow could run on with custom compilation from source. <a href="https://github.com/lhelontra/tensorflow-on-arm" target="_blank" rel="noopener noreferrer">GitHub</a> No Official support, and it is probably CPU-only.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="pytorch"></a>PyTorch<a aria-hidden="true" tabindex="-1" class="hash-link" href="#pytorch" title="Direct link to heading">#</a></h3><p>Not Possible: Requires CUDA as the sole option for dependencies.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="paddle-lite-by-baidu"></a>Paddle-Lite by Baidu<a aria-hidden="true" tabindex="-1" class="hash-link" href="#paddle-lite-by-baidu" title="Direct link to heading">#</a></h3><p><img src="https://avatars3.githubusercontent.com/u/23534030?s=200&amp;v=4"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="key-features"></a>Key Features<a aria-hidden="true" tabindex="-1" class="hash-link" href="#key-features" title="Direct link to heading">#</a></h4><ul><li>Official support Mali GPU (OpenCL), Andreno GPU, Apple Metal GPU</li><li>Official support Kirin NPU, MTK APU, RK NPU</li><li>Future support includes Cambricon and Bitmain</li><li>Available in both Lite and Full (CUDA) version, tested on Jetson TX2</li><li>Support Yolov3 since version 2.0 (launched in late 2019)</li><li>5K GitHub Stars, QQ support group 696965088</li><li>Tons of <a href="https://blog.csdn.net/PaddlePaddle/article/details/104912335" target="_blank" rel="noopener noreferrer">improments and tricks</a> and tools like <a href="https://paddle-lite.readthedocs.io/zh/latest/user_guides/x2paddle.html" target="_blank" rel="noopener noreferrer">x2paddle</a><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9zS2lhMUZLRmlhZmdpYXk3SjhqaWNUYm05M3lZd0tjM2xiOW04WWd0ZGhQc0hUUncwSGVRYWljYUtrRXNpY05CUFhLa3ZHRFlCMXhUSDIwblNPcnVTVGdLRklxUS82NDA?x-oss-process=image/format,png"></li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="key-drawbacks"></a>Key Drawbacks<a aria-hidden="true" tabindex="-1" class="hash-link" href="#key-drawbacks" title="Direct link to heading">#</a></h4><ul><li>Still transiting older versions of Paddle-Mobile to the rebranded Paddle-Lite</li><li>Reported that documentation is not friendly, for starting. (Refering to version 1, not sure if version 2 improved) <a href="https://www.zhihu.com/question/341980046" target="_blank" rel="noopener noreferrer">Zhihu</a>, <a href="https://www.zhihu.com/question/341980046/answer/799827299" target="_blank" rel="noopener noreferrer">Developer Reply</a></li></ul><p><a href="https://paddlepaddle.github.io/Paddle-Lite/develop/benchmark/" target="_blank" rel="noopener noreferrer">Paddle-Lite benchmark</a>,
<a href="https://github.com/PaddlePaddle/Paddle-Lite-Demo" target="_blank" rel="noopener noreferrer">Paddle-Lite Demo</a>,
<a href="https://zhuanlan.zhihu.com/p/103082836" target="_blank" rel="noopener noreferrer">Release Blog</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="bottom-line"></a>Bottom Line<a aria-hidden="true" tabindex="-1" class="hash-link" href="#bottom-line" title="Direct link to heading">#</a></h4><ul><li>Interesting framework to test Kirin NPU (Kirin 970 1.92TFLOPs) and RK NPU (RK1808, RK1806，not currently RK3399Pro) performance. However, currently those chips are not miniturisable.</li><li>Hi35xx chips (Hi3559A NPU: Dual core NNIE; Hi3516A, 2TOPS) not supported, probably need to use NNIE instead (takes in caffe format)</li><li>Still good to use it for complete GPU support</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="ncnn-by-tencent"></a>NCNN by Tencent<a aria-hidden="true" tabindex="-1" class="hash-link" href="#ncnn-by-tencent" title="Direct link to heading">#</a></h3><p><img src="https://raw.githubusercontent.com/Tencent/ncnn/master/images/256-ncnn.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="key-features-1"></a>Key Features<a aria-hidden="true" tabindex="-1" class="hash-link" href="#key-features-1" title="Direct link to heading">#</a></h4><ul><li>Design to be light-weight (library &lt;1MB)</li><li>Optimised memory access, written all in C++</li><li>ARM NEON Assembly optimisation, ARM big.LITTLE CPU optimisation</li><li>Utilise <a href="https://github.com/Tencent/ncnn/wiki/FAQ-ncnn-vulkan" target="_blank" rel="noopener noreferrer">VulKan API</a>, for GPU acceleration</li><li>Support import from caffe/pytorch/mxnet/onnx</li><li>QQ Support Group: 637093648</li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="key-drawbacks-1"></a>Key Drawbacks<a aria-hidden="true" tabindex="-1" class="hash-link" href="#key-drawbacks-1" title="Direct link to heading">#</a></h4><ul><li>Focused on Android platform, many users. <em>But on Linux platform untested.</em><img src="https://img-blog.csdnimg.cn/20190224124039169.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3l1YW5sdWx1,size_16,color_FFFFFF,t_70" alt="https://blog.csdn.net/yuanlulu/article/details/87902106"></li><li>Compilation instruction includes Hisilicon (Hi35xx) and Arm64, but not sure if GPU acceleration and NPU acceleration is enabled</li></ul><p>Tencent NCNN claims that their CPU optimisation is quite good (<strong>fastest among open-sourced ones</strong>), might even outperform the built-in GPU</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="bottomline-1"></a>Bottomline<a aria-hidden="true" tabindex="-1" class="hash-link" href="#bottomline-1" title="Direct link to heading">#</a></h4><ul><li>Claimes to be fast, with good CPU optimisation</li><li>could be a good GPU benchmark as well (using Vulkan instead of OpenCL)</li></ul><p><a href="https://github.com/Tencent/ncnn/wiki/vulkan-conformance-test" target="_blank" rel="noopener noreferrer">MaliG72</a> looking good with ncnn</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="mnn-by-alibaba"></a>MNN by Alibaba<a aria-hidden="true" tabindex="-1" class="hash-link" href="#mnn-by-alibaba" title="Direct link to heading">#</a></h3><p><a href="https://arxiv.org/pdf/2002.12418.pdf" target="_blank" rel="noopener noreferrer">Publication</a>
<img src="https://github.com/alibaba/MNN/raw/master/doc/banner.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="key-features-2"></a>Key Features<a aria-hidden="true" tabindex="-1" class="hash-link" href="#key-features-2" title="Direct link to heading">#</a></h4><ul><li>Claimed CPU assembly optimisation</li><li>Android: OpenCL, Vulkan, OpenGL support (<strong>very comprehensive!</strong>)</li><li>Appear to support ordinary Linux too, from <a href="https://www.yuque.com/mnn/en/build_linux" target="_blank" rel="noopener noreferrer">doc</a></li><li>Lightweight</li><li>Support Tensorflow, Tensorflow Lite, Caffe and ONNX (PyTorch/MXNet)</li><li>Feels to be <a href="https://www.alibabacloud.com/blog/alibaba-open-source-and-lightweight-deep-learning-inference-engine---mobile-neural-network-mnn_595318" target="_blank" rel="noopener noreferrer">research oriented</a></li></ul><p><img src="https://cdn.nlark.com/yuque/0/2020/png/547206/1588926160169-1ff710f0-c56e-466c-beed-48f0e2e959cd.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_10%2Ctext_QWxpYmFiYQ%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fresize%2Cw_1282" alt="Roadmap"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="key-drawbacks-2"></a>Key Drawbacks<a aria-hidden="true" tabindex="-1" class="hash-link" href="#key-drawbacks-2" title="Direct link to heading">#</a></h4><ul><li>Just released as open source (2019?) (semi-automated search architecture for better mobile deployment)</li><li>The features looks too good to be ture. But lets hope for the best.</li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="bottomline-2"></a>Bottomline<a aria-hidden="true" tabindex="-1" class="hash-link" href="#bottomline-2" title="Direct link to heading">#</a></h4><ul><li>The paper is worth reading</li><li>A new option with good potential</li></ul><p><a href="https://zhuanlan.zhihu.com/p/96022321" target="_blank" rel="noopener noreferrer">blog</a></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="mxnet-by-amazon"></a>MXNet by Amazon<a aria-hidden="true" tabindex="-1" class="hash-link" href="#mxnet-by-amazon" title="Direct link to heading">#</a></h3><p><a href="https://github.com/apache/incubator-mxnet" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-mxnet</a></p><p><img src="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mxnet_logo_2.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="key-features-3"></a>Key Features<a aria-hidden="true" tabindex="-1" class="hash-link" href="#key-features-3" title="Direct link to heading">#</a></h4><ul><li>Used in Universities to teach deep learning classes (Famous book: dive into deep learning)</li><li>Great documentation, looks easy to get started with Python</li><li>Integration with TVM</li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="key-drawbacks-3"></a>Key Drawbacks<a aria-hidden="true" tabindex="-1" class="hash-link" href="#key-drawbacks-3" title="Direct link to heading">#</a></h4><ul><li>seems no support for ARM GPU or NPU</li><li>Comparison with tvm, from <a href="https://tvm.apache.org/2018/01/16/opt-mali-gpu" target="_blank" rel="noopener noreferrer">tvm blog</a> back in 2018. Results not good for MXNet.
<img src="https://tvm.apache.org/images/opt-mali/end2end.png"></li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="bottomline-3"></a>Bottomline<a aria-hidden="true" tabindex="-1" class="hash-link" href="#bottomline-3" title="Direct link to heading">#</a></h4><ul><li>Not for us. It is for bigger machines, cluster of machines.</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="mace-by-xiaomi"></a>Mace by Xiaomi<a aria-hidden="true" tabindex="-1" class="hash-link" href="#mace-by-xiaomi" title="Direct link to heading">#</a></h3><p>Not recommanded.</p><ul><li>Does not support CUDA</li><li>Does not support popular Raspberry Pi</li><li>Hard to find non-Andriod documentation.</li><li>Xiaomi&#x27;s strength is in Quadcomm CPUs</li><li>Not as a big community using it</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="tengine-by-open-ai-lab-supported-by-arm"></a>Tengine by OPEN AI Lab (Supported by ARM)<a aria-hidden="true" tabindex="-1" class="hash-link" href="#tengine-by-open-ai-lab-supported-by-arm" title="Direct link to heading">#</a></h3><p><a href="https://github.com/OAID/Tengine" target="_blank" rel="noopener noreferrer">https://github.com/OAID/Tengine</a></p><p>Not recommended. only ARM CPU acceleration? But claim to be fast?</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="arm-nn"></a>ARM NN<a aria-hidden="true" tabindex="-1" class="hash-link" href="#arm-nn" title="Direct link to heading">#</a></h3><p>Not recommended. Should not go here, again, platform dependent!</p><p>It should be based on ARM Compute Library.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="sensetime-parrots-ppl"></a>SenseTime Parrots (PPL)<a aria-hidden="true" tabindex="-1" class="hash-link" href="#sensetime-parrots-ppl" title="Direct link to heading">#</a></h3><p>Closed source, but claim to have the best performance among the commercial solutions.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="tvm-an-aggressive-step-auto-tuning"></a>TVM (An Aggressive Step: Auto Tuning)<a aria-hidden="true" tabindex="-1" class="hash-link" href="#tvm-an-aggressive-step-auto-tuning" title="Direct link to heading">#</a></h2><p><a href="https://dl.acm.org/doi/pdf/10.1145/3229762.3229764?download=true" target="_blank" rel="noopener noreferrer">TVM paper</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="key-features-4"></a>Key Features<a aria-hidden="true" tabindex="-1" class="hash-link" href="#key-features-4" title="Direct link to heading">#</a></h4><ul><li>Support ARM GPU (uda, opencl or vulkan backend)</li><li>Could add custom accelerator support through VTA (e.g. FPGA)</li><li>Machine Learning the best combination to utilise the heterogeneous hardware</li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="key-drawbacks-4"></a>Key Drawbacks<a aria-hidden="true" tabindex="-1" class="hash-link" href="#key-drawbacks-4" title="Direct link to heading">#</a></h4><ul><li>Might be too many things varying at the same time, hard to debug?</li></ul><p>Integrating TVM into PyTorch
<a href="https://tvm.apache.org/2019/05/30/pytorch-frontend" target="_blank" rel="noopener noreferrer">https://tvm.apache.org/2019/05/30/pytorch-frontend</a></p><p>云天励飞基于TVM
<a href="https://zhuanlan.zhihu.com/p/91826247" target="_blank" rel="noopener noreferrer">https://zhuanlan.zhihu.com/p/91826247</a>
<a href="https://www.intellif.com/int/product/list15.html" target="_blank" rel="noopener noreferrer">https://www.intellif.com/int/product/list15.html</a></p><p>Optimizing Mobile Deep Learning on ARM GPU with TVM
<a href="https://tvm.apache.org/2018/01/16/opt-mali-gpu" target="_blank" rel="noopener noreferrer">https://tvm.apache.org/2018/01/16/opt-mali-gpu</a></p><p>A Unified Optimization Approach for CNN Model Inference on Integrated GPUs
<a href="https://arxiv.org/pdf/1907.02154.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1907.02154.pdf</a></p></section><footer class="row margin-vert--lg"><div class="col"><strong>Tags:</strong><a class="margin-horiz--sm" href="/blog/tags/dl">DL</a><a class="margin-horiz--sm" href="/blog/tags/embedded">embedded</a><a class="margin-horiz--sm" href="/blog/tags/framework">framework</a></div></footer></article><div><a href="https://github.com/chengguizi/chengguizi.github.io/blog/2020-05-26-about-vulkan.md" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="1.2em" width="1.2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 40 40" style="margin-right:0.3em;vertical-align:sub"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="margin-vert--xl"><nav class="pagination-nav" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/tonemapping-intro"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">« Introduction to Tonemapping</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/guitar-fretboard"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Memeorising Guitar Fretboard »</div></a></div></nav></div></div></div></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><h4 class="footer__title">Docs</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/doc1">Style Guide</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/doc2">Second Doc</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Community</h4><ul class="footer__items"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow</a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord</a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">More</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub</a></li></ul></div></div><div class="text--center"><div>Copyright © 2020 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/styles.0a4195cd.js"></script>
<script src="/runtime~main.0a9401a8.js"></script>
<script src="/main.cb1cffdb.js"></script>
<script src="/1.2d582883.js"></script>
<script src="/2.2b91fbf4.js"></script>
<script src="/3.88e3f531.js"></script>
<script src="/ccc49370.75c65c31.js"></script>
<script src="/9ea8503f.fe1359cf.js"></script>
</body>
</html>